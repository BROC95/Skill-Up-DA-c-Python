INFO - Dependencies all met for <TaskInstance: ETL_dag.Transform_B2 scheduled__2018-03-12T00:00:00+00:00 [queued]>
INFO - Dependencies all met for <TaskInstance: ETL_dag.Transform_B2 scheduled__2018-03-12T00:00:00+00:00 [queued]>
INFO - 
--------------------------------------------------------------------------------
INFO - Starting attempt 1 of 2
INFO - 
--------------------------------------------------------------------------------
ERROR - Did not find openlineage.yml and OPENLINEAGE_URL is not set
WARNING - Couldn't initialize transport; will print events to console.
INFO - {"eventTime": "2022-11-11T00:28:08.695049Z", "eventType": "START", "inputs": [], "job": {"facets": {}, "name": "ETL_dag.Transform_B2", "namespace": "default"}, "outputs": [], "producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "run": {"facets": {"airflow_runArgs": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "externalTrigger": false}, "airflow_version": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "airflowVersion": "2.4.2+astro.1", "openlineageAirflowVersion": "0.15.1", "operator": "airflow.operators.python.PythonOperator", "taskInfo": {"_BaseOperator__from_mapped": false, "_BaseOperator__init_kwargs": {"dag": {"dag_id": "ETL_dag", "schedule_interval": "@daily"}, "owner": "BROC95", "python_callable": "<function extract at 0x7f6249a83af0>", "retries": 1, "retry_delay": "0:05:00", "start_date": "2018-03-01T00:00:00+00:00", "task_id": "Transform_B2"}, "_BaseOperator__instantiated": true, "_dag": {"dag_id": "ETL_dag", "schedule_interval": "@daily"}, "_log": "<Logger airflow.task.operators (INFO)>", "depends_on_past": false, "do_xcom_push": true, "downstream_task_ids": "{'Load_B2'}", "email_on_failure": true, "email_on_retry": true, "executor_config": {}, "ignore_first_depends_on_past": true, "inlets": [], "op_args": [], "op_kwargs": {}, "outlets": [], "owner": "BROC95", "params": "{}", "pool": "default_pool", "pool_slots": 1, "priority_weight": 1, "python_callable": "<function extract at 0x7f6249a83af0>", "queue": "default", "retries": 1, "retry_delay": "0:05:00", "retry_exponential_backoff": false, "show_return_value_in_logs": true, "start_date": "2018-03-01T00:00:00+00:00", "task_group": "<airflow.utils.task_group.TaskGroup object at 0x7f624996ef40>", "task_id": "Transform_B2", "trigger_rule": "all_success", "upstream_task_ids": "{'Extract_B2'}", "wait_for_downstream": false, "weight_rule": "downstream"}}, "nominalTime": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/NominalTimeRunFacet", "nominalStartTime": "2018-03-12T00:00:00.000000Z"}, "parent": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/ParentRunFacet", "job": {"name": "ETL_dag", "namespace": "default"}, "run": {"runId": "d901add2-505f-363f-bdbe-c85dcab4f316"}}, "parentRun": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/ParentRunFacet", "job": {"name": "ETL_dag", "namespace": "default"}, "run": {"runId": "d901add2-505f-363f-bdbe-c85dcab4f316"}}, "unknownSourceAttribute": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "unknownItems": [{"name": "PythonOperator", "properties": {"_BaseOperator__from_mapped": false, "_BaseOperator__init_kwargs": {"dag": "<<non-serializable: DAG>>", "owner": "BROC95", "python_callable": "<<non-serializable: function>>", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "start_date": "<<non-serializable: DateTime>>", "task_id": "Transform_B2"}, "_BaseOperator__instantiated": true, "_dag": "<<non-serializable: DAG>>", "_log": "<<non-serializable: Logger>>", "depends_on_past": false, "do_xcom_push": true, "downstream_task_ids": [], "email_on_failure": true, "email_on_retry": true, "executor_config": {}, "ignore_first_depends_on_past": true, "inlets": [], "op_args": [], "op_kwargs": {}, "outlets": [], "owner": "BROC95", "params": "<<non-serializable: ParamsDict>>", "pool": "default_pool", "pool_slots": 1, "priority_weight": 1, "python_callable": "<<non-serializable: function>>", "queue": "default", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "retry_exponential_backoff": false, "show_return_value_in_logs": true, "start_date": "<<non-serializable: DateTime>>", "task_group": "<<non-serializable: TaskGroup>>", "task_id": "Transform_B2", "trigger_rule": "all_success", "upstream_task_ids": [], "wait_for_downstream": false, "weight_rule": "downstream"}, "type": "operator"}]}}, "runId": "6a943abf-ba6a-4cca-8e97-88cc2370eee0"}}
INFO - TaskInstance Details: dag_id=ETL_dag, task_id=Transform_B2, dagrun_id=scheduled__2018-03-12T00:00:00+00:00, map_index=-1, run_start_date=2022-11-11 00:28:08.695049+00:00, try_number=1, job_id=122, op_classpath=airflow.operators.python.PythonOperator
INFO - Executing <Task(PythonOperator): Transform_B2> on 2018-03-12 00:00:00+00:00
INFO - Started process 763 to run task
INFO - Running: ['airflow', 'tasks', 'run', 'ETL_dag', 'Transform_B2', 'scheduled__2018-03-12T00:00:00+00:00', '--job-id', '122', '--raw', '--subdir', 'DAGS_FOLDER/factory.py', '--cfg-path', '/tmp/tmpx68nvpz6']
INFO - Job 122: Subtask Transform_B2
WARNING - /usr/local/lib/python3.9/site-packages/airflow/configuration.py:545 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
INFO - Running <TaskInstance: ETL_dag.Transform_B2 scheduled__2018-03-12T00:00:00+00:00 [running]> on host 5bee9a49f133
INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=BROC95
AIRFLOW_CTX_DAG_ID=ETL_dag
AIRFLOW_CTX_TASK_ID=Transform_B2
AIRFLOW_CTX_EXECUTION_DATE=2018-03-12T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-12T00:00:00+00:00
INFO - '2022-11-11' - GBUNSalvador_dag_elt - GBUNSalvador_dag_elt
INFO - '2022-11-11' - GBUNSalvador_dag_elt - Extract
INFO - '2022-11-11' - GBUNSalvador_dag_elt - Connect: alkemy_db
INFO - '2022-11-11' - airflow.hooks.base - Using connection ID 'alkemy_db' for task execution.
